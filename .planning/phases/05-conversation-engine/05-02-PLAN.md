---
phase: 05-conversation-engine
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/conversation/tools.ts
  - src/conversation/tool-loop.ts
autonomous: true

must_haves:
  truths:
    - "LLM tool calls are executed and results fed back until a final text response"
    - "Tool arguments are validated through Zod schemas before execution"
    - "Destructive tool calls halt the loop and return a pending confirmation instead of executing"
    - "The loop has a bounded iteration limit to prevent infinite cycling"
    - "Tool definitions are generated from a registry with Zod-to-JSON-Schema conversion"
  artifacts:
    - path: "src/conversation/tools.ts"
      provides: "Tool registry with definition builder and executor map"
      exports: ["createToolRegistry", "defineTool", "ToolRegistry"]
    - path: "src/conversation/tool-loop.ts"
      provides: "Tool call loop that drives LLM conversation to completion"
      exports: ["toolCallLoop"]
  key_links:
    - from: "src/conversation/tool-loop.ts"
      to: "src/conversation/tools.ts"
      via: "registry.get(toolCall.function.name)"
      pattern: "registry"
    - from: "src/conversation/tool-loop.ts"
      to: "openai"
      via: "client.chat.completions.create()"
      pattern: "chat\\.completions\\.create"
    - from: "src/conversation/tools.ts"
      to: "zod"
      via: "z.toJSONSchema() for tool parameter schemas"
      pattern: "toJSONSchema"
---

<objective>
Build the tool registry and tool call loop -- the core engine that sends messages to the LLM, processes tool calls, validates arguments, executes tools, and re-prompts until a final text response (or a destructive action requiring confirmation).

Purpose: This is the beating heart of the conversation engine. It connects the LLM to Sonarr/Radarr operations through a controlled loop with confirmation interception for destructive actions.
Output: Tool registry (definition builder + executor map), tool call loop with confirmation tier interception.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-conversation-engine/05-RESEARCH.md
@.planning/phases/05-conversation-engine/05-01-SUMMARY.md
@src/conversation/types.ts
@src/conversation/llm.ts
@src/conversation/history.ts
@src/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Tool registry with Zod-to-JSON-Schema definitions</name>
  <files>src/conversation/tools.ts</files>
  <action>
Create the tool registry module. This manages tool definitions (for the LLM) and their corresponding executors (for runtime).

**defineTool(name, description, parameters, tier, execute)** -- Helper function that:
1. Takes a name (string), description (string), parameters (Zod schema), tier (ConfirmationTier), and execute function.
2. Converts the Zod schema to JSON Schema using `z.toJSONSchema(parameters, { target: "draft-7" })` from Zod v4's native API.
3. Returns a ToolDefinition object with the OpenAI ChatCompletionTool format:
   ```
   {
     definition: {
       type: "function",
       function: { name, description, parameters: jsonSchema }
     },
     tier,
     paramSchema: parameters,  // Keep original Zod schema for runtime validation
     execute
   }
   ```

**ToolRegistry** -- A class (or Map wrapper) that:
- Stores ToolDefinition entries keyed by function name
- `register(tool: ToolDefinition)`: adds a tool to the registry
- `get(name: string)`: returns a ToolDefinition or undefined
- `getDefinitions()`: returns ChatCompletionTool[] array for passing to the OpenAI API
- `isDestructive(name: string)`: returns boolean (checks if the tool's tier === "destructive")

**createToolRegistry()** -- Factory that creates a new ToolRegistry instance. Does NOT register any concrete tools -- that happens in Phase 6/7 when search/add/remove tools are built. This phase only builds the framework.

However, register ONE minimal "hello world" tool to validate the end-to-end flow:

`check_status` tool:
- Description: "Check if media servers (Sonarr and Radarr) are reachable"
- Parameters: empty object `z.object({})`
- Tier: "safe"
- Execute: Returns a JSON object with sonarr: "connected"/"unavailable" and radarr: "connected"/"unavailable" based on whether context.sonarr and context.radarr exist (non-null)

This minimal tool is enough to validate the tool call loop end-to-end without depending on Phase 6/7.

Import z from "zod" and use `z.toJSONSchema()` directly -- do NOT use `zodFunction()` from the OpenAI SDK helpers (Zod v4 compatibility issues per research).
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. `npm run check` passes
3. Verify that `defineTool` produces valid ChatCompletionTool JSON structure
  </verify>
  <done>
- defineTool converts Zod schemas to JSON Schema and wraps in OpenAI tool format
- ToolRegistry stores, retrieves, and lists tool definitions
- createToolRegistry returns a registry with one check_status tool for validation
- isDestructive correctly identifies destructive tools
  </done>
</task>

<task type="auto">
  <name>Task 2: Tool call loop with confirmation interception</name>
  <files>src/conversation/tool-loop.ts</files>
  <action>
Create the tool call loop -- a while-loop that calls the LLM, processes tool calls, and re-calls until a final text response or confirmation prompt.

**toolCallLoop(params)** -- Async function with params:
```
{
  client: OpenAI,
  model: string,
  messages: ChatCompletionMessageParam[],
  registry: ToolRegistry,
  context: ToolContext,
  log: FastifyBaseLogger,
  maxIterations?: number  // default 10
}
```

Returns `ToolCallLoopResult` (from types.ts): `{ reply, pendingConfirmation?, messagesConsumed }`.

Algorithm:
1. Get tool definitions from registry: `registry.getDefinitions()`
2. Loop up to maxIterations:
   a. Call `client.chat.completions.create({ model, messages, tools })` -- NO streaming, NO tool_choice (Ollama compat per research)
   b. Get `choice = response.choices[0]`; throw if missing
   c. Push the assistant message onto messages array
   d. If `finish_reason === "stop"` OR `tool_calls` is empty/undefined:
      - Return `{ reply: assistantMessage.content ?? "", messagesConsumed: messages }`
   e. For each tool call in `assistantMessage.tool_calls`:
      - Parse arguments: `JSON.parse(toolCall.function.arguments)`
      - Look up tool in registry: `registry.get(toolCall.function.name)`
      - If tool not found: push a tool result message with error content `{ error: "Unknown tool: {name}" }` and continue
      - Validate arguments through the tool's Zod paramSchema. If validation fails: push tool result with error content containing the Zod error message
      - **Check confirmation tier**: If `registry.isDestructive(toolCall.function.name)`:
        - Format a confirmation prompt: "I'd like to {functionName} with {summary of args}. Are you sure? (yes/no)"
        - Return `{ reply: confirmationPrompt, pendingConfirmation: { userId: context.userId, functionName, arguments: JSON.stringify(parsedArgs), promptText: confirmationPrompt, expiresAt: new Date(Date.now() + 5 * 60 * 1000) }, messagesConsumed: messages }`
        - NOTE: Do NOT execute the tool. Do NOT push a tool result. The loop exits here.
      - Execute the tool: `await tool.execute(parsedArgs, context)`
      - Wrap result in a tool message: `{ role: "tool", tool_call_id: toolCall.id, content: JSON.stringify(result) }`
      - Push tool result message onto messages
      - Log tool execution: `log.info({ tool: toolCall.function.name }, "Tool executed")`
   f. Continue loop (re-call LLM with updated messages including tool results)
3. If loop exhausts maxIterations: return `{ reply: "I'm having trouble processing that. Could you try rephrasing?", messagesConsumed: messages }`

Important implementation details:
- Wrap the entire tool execution in try/catch. If a tool throws, push a tool result message with `{ error: err.message }` content so the LLM can recover gracefully.
- Log the raw response at debug level for development troubleshooting (per research recommendation).
- When destructive action is detected and there are multiple tool calls in the same response, only process up to the first destructive one. Non-destructive calls before it in the array should already be executed (they come earlier in the for-loop).
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. `npm run check` passes
3. Review the loop logic: confirm it handles (a) no tool calls -> returns text, (b) safe tool calls -> executes and re-prompts, (c) destructive tool calls -> returns confirmation, (d) unknown tools -> returns error to LLM, (e) max iterations -> returns fallback
  </verify>
  <done>
- toolCallLoop drives LLM conversation through tool calls to a final text response
- Destructive tools are intercepted before execution with a confirmation prompt
- Tool arguments are validated through Zod schemas
- Unknown tools and execution errors produce graceful error messages back to the LLM
- Loop is bounded by maxIterations (default 10)
- All messages (including tool calls and results) are tracked in messagesConsumed for persistence
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` -- all files compile
2. `npm run check` -- Biome passes
3. Tool registry produces valid OpenAI ChatCompletionTool format
4. Tool call loop handles all five paths: text response, safe tool, destructive tool, unknown tool, max iterations
</verification>

<success_criteria>
- Tool registry supports registration, lookup, and definition listing
- defineTool uses z.toJSONSchema() for Zod-to-JSON-Schema conversion (not zodFunction)
- One check_status tool registered for end-to-end validation
- Tool call loop implements the full LLM tool calling protocol
- Destructive actions are intercepted before execution and return pending confirmation
- Tool arguments are Zod-validated before execution
- Error handling is graceful (errors fed back to LLM as tool results)
</success_criteria>

<output>
After completion, create `.planning/phases/05-conversation-engine/05-02-SUMMARY.md`
</output>
